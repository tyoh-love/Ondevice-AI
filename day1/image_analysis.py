from transformers import AutoModel, AutoTokenizer
import torch
from PIL import Image
import matplotlib.pyplot as plt

class ImageUnderstandingAI:
    """ì´ë¯¸ì§€ë¥¼ ì´í•´í•˜ëŠ” ë˜‘ë˜‘í•œ AI"""
    
    def __init__(self):
        """MiniCPM-O 2.6 ëª¨ë¸ ì´ˆê¸°í™”"""
        print("ğŸ–¼ï¸ ì´ë¯¸ì§€ ì´í•´ AIë¥¼ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        # MiniCPM-O-2.6 uses the same model as MiniCPM-V-2.6
        model_name = "openbmb/MiniCPM-V-2_6"
        
        # í† í¬ë‚˜ì´ì €: í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë³€í™˜
        self.tokenizer = AutoTokenizer.from_pretrained(
            model_name,
            trust_remote_code=True  # ì»¤ìŠ¤í…€ ì½”ë“œ ì‹¤í–‰ í—ˆìš©
        )
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = AutoModel.from_pretrained(
            model_name,
            trust_remote_code=True,
            torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32
        )
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = self.model.to(self.device)
        
        print(f"âœ… ì´ë¯¸ì§€ AI ì¤€ë¹„ ì™„ë£Œ! (ë””ë°”ì´ìŠ¤: {self.device})")
    
    def analyze_image(self, image_path, question="ì´ ì´ë¯¸ì§€ì—ì„œ ë¬´ì—‡ì´ ë³´ì´ë‚˜ìš”?"):
        """ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ì§ˆë¬¸ì— ë‹µí•˜ëŠ” í•¨ìˆ˜"""
        
        # 1. ì´ë¯¸ì§€ ë¡œë“œ
        print(f"ğŸ“· ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³  ìˆìŠµë‹ˆë‹¤: {image_path}")
        image = Image.open(image_path).convert('RGB')
        
        # 2. ì´ë¯¸ì§€ ì‹œê°í™”
        self.visualize_image(image, image_path)
        
        # 3. ëª¨ë¸ì— ì…ë ¥
        print(f"\nğŸ¤” AIê°€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        print(f"ì§ˆë¬¸: {question}")
        
        # ì…ë ¥ ì¤€ë¹„
        msgs = [
            {
                'role': 'user',
                'content': [
                    {'type': 'image', 'image': image},
                    {'type': 'text', 'text': question}
                ]
            }
        ]
        
        # ì¶”ë¡ 
        with torch.no_grad():
            answer = self.model.chat(
                msgs=msgs,
                tokenizer=self.tokenizer,
                max_new_tokens=200,
                temperature=0.7
            )
        
        print(f"\nğŸ¤– AIì˜ ë‹µë³€: {answer}")
        
        return answer, image
    
    def visualize_image(self, image, image_path):
        """ì´ë¯¸ì§€ë¥¼ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜"""
        plt.figure(figsize=(8, 6))
        plt.imshow(image)
        plt.title(f'ë¶„ì„í•  ì´ë¯¸ì§€: {image_path}', fontsize=14, fontweight='bold')
        plt.axis('off')
        plt.tight_layout()
        plt.show()

# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    # AI ì´ˆê¸°í™”
    image_ai = ImageUnderstandingAI()
    
    # cry.png ì´ë¯¸ì§€ ë¶„ì„
    image_path = "../cry.png"  # day1 í´ë”ì—ì„œ ì‹¤í–‰ì‹œ ìƒìœ„ í´ë”ì˜ cry.png
    
    # ì—¬ëŸ¬ ì§ˆë¬¸ìœ¼ë¡œ ë¶„ì„
    questions = [
        "ì´ ì´ë¯¸ì§€ì—ì„œ ë¬´ì—‡ì´ ë³´ì´ë‚˜ìš”?",
        "ì´ë¯¸ì§€ì˜ ë¶„ìœ„ê¸°ë‚˜ ê°ì •ì€ ì–´ë–¤ê°€ìš”?",
        "ì´ë¯¸ì§€ì— ìˆëŠ” ì‚¬ëŒì´ë‚˜ ìºë¦­í„°ì˜ í‘œì •ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ì´ ì´ë¯¸ì§€ê°€ ì „ë‹¬í•˜ë ¤ëŠ” ë©”ì‹œì§€ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?"
    ]
    
    print("\n" + "="*50)
    print("cry.png ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘")
    print("="*50 + "\n")
    
    for i, question in enumerate(questions, 1):
        print(f"\n[ì§ˆë¬¸ {i}]")
        answer, image = image_ai.analyze_image(image_path, question)
        print("-"*50)