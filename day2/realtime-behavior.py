# smart_security_system.py - ìŠ¤ë§ˆíŠ¸ ë³´ì•ˆ ì‹œìŠ¤í…œ

import cv2
import torch
import numpy as np
from ultralytics import YOLO
import supervision as sv
from collections import defaultdict, deque
import time
from datetime import datetime
import json
import os
import threading
import queue
from typing import Dict, List, Tuple, Optional
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.image import MIMEImage

class SmartSecuritySystem:
    """AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë³´ì•ˆ ì‹œìŠ¤í…œ"""
    
    def __init__(self, config: Dict = None):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        print("ğŸ”’ ìŠ¤ë§ˆíŠ¸ ë³´ì•ˆ ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        # ì„¤ì •
        self.config = config or self.get_default_config()
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.init_models()
        
        # ì¶”ì ê¸° ì´ˆê¸°í™”
        self.tracker = sv.ByteTrack()
        
        # ë°ì´í„° ì €ì¥ì†Œ
        self.init_storage()
        
        # ì•Œë¦¼ ì‹œìŠ¤í…œ
        self.init_notification_system()
        
        print("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
    
    def get_default_config(self) -> Dict:
        """ê¸°ë³¸ ì„¤ì •ê°’"""
        return {
            'yolo_model': 'yolo11m.pt',
            'confidence_threshold': 0.5,
            'max_tracked_objects': 50,
            'alert_cooldown': 30,  # ì´ˆ
            'recording_path': 'security_recordings',
            'suspicious_behaviors': {
                'loitering': {'duration': 60, 'area': 100},  # 60ì´ˆ ì´ìƒ ë¨¸ë¬´ë¥´ê¸°
                'running': {'speed_threshold': 5.0},  # ë¹ ë¥¸ ì›€ì§ì„
                'intrusion': {'restricted_zones': []},  # ì œí•œ êµ¬ì—­ ì¹¨ì…
                'crowding': {'max_people': 10},  # ê³¼ë°€
                'abandoned_object': {'duration': 300}  # 5ë¶„ ì´ìƒ ë°©ì¹˜ëœ ë¬¼ì²´
            },
            'notification': {
                'email': None,
                'webhook': None
            }
        }
    
    def init_models(self):
        """AI ëª¨ë¸ ì´ˆê¸°í™”"""
        print("  ğŸ§  AI ëª¨ë¸ì„ ë¡œë”©í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        # YOLO ëª¨ë¸
        self.yolo = YOLO(self.config['yolo_model'])
        
        # í–‰ë™ ë¶„ë¥˜ê¸° (ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜)
        self.behavior_analyzer = BehaviorAnalyzer(self.config['suspicious_behaviors'])
        
    def init_storage(self):
        """ë°ì´í„° ì €ì¥ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.storage_path = self.config['recording_path']
        os.makedirs(self.storage_path, exist_ok=True)
        
        # ì¶”ì  ë°ì´í„°
        self.track_history = defaultdict(lambda: {
            'positions': deque(maxlen=300),  # 10ì´ˆ @ 30fps
            'timestamps': deque(maxlen=300),
            'class': None,
            'first_seen': None,
            'last_seen': None,
            'alerts': []
        })
        
        # ì´ë²¤íŠ¸ ë¡œê·¸
        self.event_log = []
        
    def init_notification_system(self):
        """ì•Œë¦¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.alert_queue = queue.Queue()
        self.last_alert_time = defaultdict(float)
        
        # ì•Œë¦¼ ì²˜ë¦¬ ìŠ¤ë ˆë“œ
        self.notification_thread = threading.Thread(
            target=self.process_notifications,
            daemon=True
        )
        self.notification_thread.start()
    
    def process_frame(self, frame: np.ndarray, frame_id: int) -> Tuple[np.ndarray, List[Dict]]:
        """ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬"""
        
        # 1. ê°ì²´ íƒì§€
        results = self.yolo(frame, conf=self.config['confidence_threshold'], verbose=False)[0]
        detections = sv.Detections.from_ultralytics(results)
        
        # 2. ê°ì²´ ì¶”ì 
        tracks = self.tracker.update_with_detections(detections)
        
        # 3. ì¶”ì  ë°ì´í„° ì—…ë°ì´íŠ¸
        current_time = time.time()
        events = []
        
        for i in range(len(tracks)):
            track_id = tracks.tracker_id[i]
            class_id = tracks.class_id[i]
            class_name = self.yolo.names[class_id]
            bbox = tracks.xyxy[i]
            
            # ì¤‘ì‹¬ì  ê³„ì‚°
            center = ((bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2)
            
            # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            history = self.track_history[track_id]
            history['positions'].append(center)
            history['timestamps'].append(current_time)
            history['class'] = class_name
            
            if history['first_seen'] is None:
                history['first_seen'] = current_time
                events.append({
                    'type': 'new_object',
                    'track_id': track_id,
                    'class': class_name,
                    'time': current_time
                })
            
            history['last_seen'] = current_time
        
        # 4. í–‰ë™ ë¶„ì„
        suspicious_activities = self.behavior_analyzer.analyze(
            self.track_history, current_time
        )
        
        # 5. ì•Œë¦¼ ìƒì„±
        for activity in suspicious_activities:
            if self.should_send_alert(activity):
                self.alert_queue.put({
                    'activity': activity,
                    'frame': frame.copy(),
                    'time': current_time
                })
                events.append(activity)
        
        # 6. ì‹œê°í™”
        annotated_frame = self.visualize_results(
            frame, tracks, suspicious_activities
        )
        
        return annotated_frame, events
    
    def should_send_alert(self, activity: Dict) -> bool:
        """ì•Œë¦¼ì„ ë³´ë‚¼ì§€ ê²°ì •"""
        alert_type = activity['type']
        current_time = time.time()
        
        # ì¿¨ë‹¤ìš´ í™•ì¸
        if current_time - self.last_alert_time[alert_type] < self.config['alert_cooldown']:
            return False
        
        self.last_alert_time[alert_type] = current_time
        return True
    
    def visualize_results(self, frame: np.ndarray, tracks: sv.Detections, 
                         activities: List[Dict]) -> np.ndarray:
        """ê²°ê³¼ ì‹œê°í™”"""
        annotated = frame.copy()
        
        # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        box_annotator = sv.BoxAnnotator()
        annotated = box_annotator.annotate(scene=annotated, detections=tracks)
        
        # ì¶”ì  IDì™€ í´ë˜ìŠ¤ í‘œì‹œ
        for i in range(len(tracks)):
            track_id = tracks.tracker_id[i]
            class_id = tracks.class_id[i]
            class_name = self.yolo.names[class_id]
            bbox = tracks.xyxy[i]
            
            # ë¼ë²¨
            label = f"ID:{track_id} {class_name}"
            
            # ì˜ì‹¬ í–‰ë™ì´ ìˆëŠ” ê²½ìš° ê°•ì¡°
            is_suspicious = any(
                activity.get('track_id') == track_id 
                for activity in activities
            )
            
            color = (0, 0, 255) if is_suspicious else (0, 255, 0)
            
            cv2.putText(
                annotated,
                label,
                (int(bbox[0]), int(bbox[1] - 10)),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                color,
                2
            )
        
        # ìƒíƒœ í‘œì‹œ
        self.draw_status(annotated, len(tracks), activities)
        
        return annotated
    
    def draw_status(self, frame: np.ndarray, num_objects: int, activities: List[Dict]):
        """ìƒíƒœ ì •ë³´ í‘œì‹œ"""
        h, w = frame.shape[:2]
        
        # ìƒë‹¨ ì •ë³´ ë°”
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, 0), (w, 50), (0, 0, 0), -1)
        frame[:50] = cv2.addWeighted(overlay[:50], 0.7, frame[:50], 0.3, 0)
        
        # ì‹œê°„
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        cv2.putText(frame, current_time, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ê°ì²´ ìˆ˜
        cv2.putText(frame, f"Objects: {num_objects}", (300, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ê²½ê³ 
        if activities:
            alert_text = f"ALERT: {activities[0]['type']}"
            cv2.putText(frame, alert_text, (500, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
    
    def process_notifications(self):
        """ì•Œë¦¼ ì²˜ë¦¬ ìŠ¤ë ˆë“œ"""
        while True:
            try:
                alert = self.alert_queue.get(timeout=1)
                self.send_notification(alert)
            except queue.Empty:
                continue
    
    def send_notification(self, alert: Dict):
        """ì•Œë¦¼ ì „ì†¡"""
        print(f"\nğŸš¨ ê²½ê³ : {alert['activity']['type']}")
        print(f"   ì‹œê°„: {datetime.fromtimestamp(alert['time'])}")
        print(f"   ì„¸ë¶€ì‚¬í•­: {alert['activity'].get('details', 'N/A')}")
        
        # ì´ë©”ì¼ ì•Œë¦¼ (ì„¤ì •ëœ ê²½ìš°)
        if self.config['notification']['email']:
            self.send_email_alert(alert)
        
        # ì›¹í›… ì•Œë¦¼ (ì„¤ì •ëœ ê²½ìš°)
        if self.config['notification']['webhook']:
            self.send_webhook_alert(alert)
        
        # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
        self.save_alert_screenshot(alert)
    
    def save_alert_screenshot(self, alert: Dict):
        """ê²½ê³  ìŠ¤í¬ë¦°ìƒ· ì €ì¥"""
        timestamp = datetime.fromtimestamp(alert['time']).strftime('%Y%m%d_%H%M%S')
        filename = f"{alert['activity']['type']}_{timestamp}.jpg"
        filepath = os.path.join(self.storage_path, filename)
        
        cv2.imwrite(filepath, alert['frame'])
        print(f"   ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {filepath}")
    
    def run_live_monitoring(self, source=0):
        """ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰"""
        print("\nğŸ¥ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        print("'q' í‚¤ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œ")
        print("'s' í‚¤ë¥¼ ëˆŒëŸ¬ ìŠ¤í¬ë¦°ìƒ· ì €ì¥")
        print("'r' í‚¤ë¥¼ ëˆŒëŸ¬ ë…¹í™” ì‹œì‘/ì¤‘ì§€")
        
        cap = cv2.VideoCapture(source)
        
        # ë¹„ë””ì˜¤ ì†ì„±
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        # ë…¹í™” ì„¤ì •
        recording = False
        video_writer = None
        
        frame_id = 0
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # í”„ë ˆì„ ì²˜ë¦¬
            annotated_frame, events = self.process_frame(frame, frame_id)
            
            # ì´ë²¤íŠ¸ ë¡œê¹…
            for event in events:
                self.log_event(event)
            
            # ë…¹í™”
            if recording and video_writer:
                video_writer.write(annotated_frame)
            
            # í™”ë©´ í‘œì‹œ
            cv2.imshow('Smart Security System', annotated_frame)
            
            # í‚¤ ì…ë ¥ ì²˜ë¦¬
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q'):
                break
            elif key == ord('s'):
                self.save_screenshot(annotated_frame)
            elif key == ord('r'):
                if not recording:
                    # ë…¹í™” ì‹œì‘
                    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                    video_path = os.path.join(self.storage_path, f"recording_{timestamp}.mp4")
                    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                    video_writer = cv2.VideoWriter(video_path, fourcc, fps, (width, height))
                    recording = True
                    print(f"ğŸ”´ ë…¹í™” ì‹œì‘: {video_path}")
                else:
                    # ë…¹í™” ì¤‘ì§€
                    video_writer.release()
                    video_writer = None
                    recording = False
                    print("â¹ï¸ ë…¹í™” ì¤‘ì§€")
            
            frame_id += 1
        
        # ì •ë¦¬
        cap.release()
        if video_writer:
            video_writer.release()
        cv2.destroyAllWindows()
        
        # ìµœì¢… ë¦¬í¬íŠ¸
        self.generate_report()
    
    def log_event(self, event: Dict):
        """ì´ë²¤íŠ¸ ë¡œê¹…"""
        event['timestamp'] = datetime.now().isoformat()
        self.event_log.append(event)
        
        # ì£¼ê¸°ì ìœ¼ë¡œ íŒŒì¼ì— ì €ì¥
        if len(self.event_log) % 100 == 0:
            self.save_event_log()
    
    def save_event_log(self):
        """ì´ë²¤íŠ¸ ë¡œê·¸ ì €ì¥"""
        log_path = os.path.join(self.storage_path, 'event_log.json')
        with open(log_path, 'w', encoding='utf-8') as f:
            json.dump(self.event_log, f, ensure_ascii=False, indent=2)
    
    def generate_report(self):
        """ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\nğŸ“Š ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸")
        print("=" * 50)
        
        # ì „ì²´ í†µê³„
        total_objects = len(self.track_history)
        print(f"ì´ ì¶”ì  ê°ì²´ ìˆ˜: {total_objects}")
        
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_counts = defaultdict(int)
        for track_data in self.track_history.values():
            if track_data['class']:
                class_counts[track_data['class']] += 1
        
        print("\ní´ë˜ìŠ¤ë³„ ê°ì²´ ìˆ˜:")
        for class_name, count in sorted(class_counts.items()):
            print(f"  - {class_name}: {count}")
        
        # ê²½ê³  í†µê³„
        alert_counts = defaultdict(int)
        for event in self.event_log:
            if event.get('type') in ['loitering', 'running', 'intrusion']:
                alert_counts[event['type']] += 1
        
        print("\nê²½ê³  ìœ í˜•ë³„ íšŸìˆ˜:")
        for alert_type, count in sorted(alert_counts.items()):
            print(f"  - {alert_type}: {count}")
        
        print("=" * 50)


class BehaviorAnalyzer:
    """í–‰ë™ ë¶„ì„ê¸°"""
    
    def __init__(self, config: Dict):
        self.config = config
    
    def analyze(self, track_history: Dict, current_time: float) -> List[Dict]:
        """ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í–‰ë™ ë¶„ì„"""
        suspicious_activities = []
        
        for track_id, history in track_history.items():
            if len(history['positions']) < 10:
                continue
            
            # 1. ë°°íšŒ ê°ì§€ (Loitering)
            loitering = self.detect_loitering(history, current_time)
            if loitering:
                suspicious_activities.append({
                    'type': 'loitering',
                    'track_id': track_id,
                    'details': loitering,
                    'time': current_time
                })
            
            # 2. ë¹ ë¥¸ ì›€ì§ì„ ê°ì§€ (Running)
            running = self.detect_running(history)
            if running:
                suspicious_activities.append({
                    'type': 'running',
                    'track_id': track_id,
                    'details': running,
                    'time': current_time
                })
            
            # 3. ë°©ì¹˜ëœ ë¬¼ì²´ ê°ì§€
            if history['class'] in ['backpack', 'suitcase', 'handbag']:
                abandoned = self.detect_abandoned_object(history, current_time)
                if abandoned:
                    suspicious_activities.append({
                        'type': 'abandoned_object',
                        'track_id': track_id,
                        'details': abandoned,
                        'time': current_time
                    })
        
        return suspicious_activities
    
    def detect_loitering(self, history: Dict, current_time: float) -> Optional[Dict]:
        """ë°°íšŒ ê°ì§€"""
        duration = current_time - history['first_seen']
        
        if duration < self.config['loitering']['duration']:
            return None
        
        # ì´ë™ ë²”ìœ„ ê³„ì‚°
        positions = list(history['positions'])
        if len(positions) < 2:
            return None
        
        xs = [p[0] for p in positions]
        ys = [p[1] for p in positions]
        
        x_range = max(xs) - min(xs)
        y_range = max(ys) - min(ys)
        area = x_range * y_range
        
        if area < self.config['loitering']['area']:
            return {
                'duration': duration,
                'area': area,
                'message': f"{duration:.1f}ì´ˆ ë™ì•ˆ ì‘ì€ ì˜ì—­ì— ë¨¸ë¬¼ëŸ¬ ìˆìŒ"
            }
        
        return None
    
    def detect_running(self, history: Dict) -> Optional[Dict]:
        """ë¹ ë¥¸ ì›€ì§ì„ ê°ì§€"""
        positions = list(history['positions'])
        timestamps = list(history['timestamps'])
        
        if len(positions) < 5:
            return None
        
        # ìµœê·¼ 5í”„ë ˆì„ì˜ ì†ë„ ê³„ì‚°
        speeds = []
        for i in range(len(positions) - 5, len(positions) - 1):
            dx = positions[i+1][0] - positions[i][0]
            dy = positions[i+1][1] - positions[i][1]
            dt = timestamps[i+1] - timestamps[i]
            
            if dt > 0:
                speed = np.sqrt(dx**2 + dy**2) / dt
                speeds.append(speed)
        
        avg_speed = np.mean(speeds) if speeds else 0
        
        if avg_speed > self.config['running']['speed_threshold']:
            return {
                'speed': avg_speed,
                'message': f"ë¹ ë¥¸ ì†ë„ë¡œ ì´ë™ ì¤‘ ({avg_speed:.1f} pixels/s)"
            }
        
        return None
    
    def detect_abandoned_object(self, history: Dict, current_time: float) -> Optional[Dict]:
        """ë°©ì¹˜ëœ ë¬¼ì²´ ê°ì§€"""
        # ë§ˆì§€ë§‰ìœ¼ë¡œ ë³¸ ì‹œê°„ í™•ì¸
        time_since_last_movement = current_time - history['last_seen']
        
        if time_since_last_movement > 1.0:  # 1ì´ˆ ì´ìƒ ì—…ë°ì´íŠ¸ ì—†ìŒ
            # ì •ì§€ ìƒíƒœ í™•ì¸
            positions = list(history['positions'])[-10:]
            if len(positions) < 10:
                return None
            
            # ìœ„ì¹˜ ë³€í™” ê³„ì‚°
            position_std = np.std([p[0] for p in positions]) + np.std([p[1] for p in positions])
            
            if position_std < 5.0:  # ê±°ì˜ ì›€ì§ì„ ì—†ìŒ
                stationary_duration = current_time - history['first_seen']
                
                if stationary_duration > self.config['abandoned_object']['duration']:
                    return {
                        'duration': stationary_duration,
                        'message': f"ë¬¼ì²´ê°€ {stationary_duration:.1f}ì´ˆ ë™ì•ˆ ë°©ì¹˜ë¨"
                    }
        
        return None


# ì›¹ ëŒ€ì‹œë³´ë“œ
def create_security_dashboard():
    """ë³´ì•ˆ ì‹œìŠ¤í…œ ì›¹ ëŒ€ì‹œë³´ë“œ"""
    import gradio as gr
    import plotly.graph_objects as go
    
    security_system = SmartSecuritySystem()
    
    def process_video_file(video_file, confidence_threshold):
        """ì—…ë¡œë“œëœ ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬"""
        if video_file is None:
            return None, "ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”"
        
        # ì„ì‹œ ì„¤ì • ì—…ë°ì´íŠ¸
        security_system.config['confidence_threshold'] = confidence_threshold
        
        cap = cv2.VideoCapture(video_file.name)
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        
        frames = []
        events = []
        frame_id = 0
        
        while len(frames) < 150:  # ìµœëŒ€ 5ì´ˆ ì²˜ë¦¬
            ret, frame = cap.read()
            if not ret:
                break
            
            annotated_frame, frame_events = security_system.process_frame(frame, frame_id)
            frames.append(annotated_frame)
            events.extend(frame_events)
            frame_id += 1
        
        cap.release()
        
        # ê²°ê³¼ ë¹„ë””ì˜¤ ìƒì„±
        output_path = "analyzed_video.mp4"
        height, width = frames[0].shape[:2]
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        for frame in frames:
            out.write(frame)
        
        out.release()
        
        # ì´ë²¤íŠ¸ ìš”ì•½
        event_summary = f"ì´ {len(events)}ê°œì˜ ì´ë²¤íŠ¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
        event_types = defaultdict(int)
        for event in events:
            event_types[event['type']] += 1
        
        for event_type, count in event_types.items():
            event_summary += f"- {event_type}: {count}íšŒ\n"
        
        return output_path, event_summary
    
    def generate_statistics():
        """í†µê³„ ê·¸ë˜í”„ ìƒì„±"""
        # ì‹œê°„ëŒ€ë³„ ê°ì²´ ìˆ˜
        hours = list(range(24))
        object_counts = np.random.poisson(10, 24)  # ì˜ˆì‹œ ë°ì´í„°
        
        fig1 = go.Figure(data=go.Bar(x=hours, y=object_counts))
        fig1.update_layout(
            title="ì‹œê°„ëŒ€ë³„ ê°ì²´ íƒì§€ ìˆ˜",
            xaxis_title="ì‹œê°„",
            yaxis_title="ê°ì²´ ìˆ˜"
        )
        
        # í´ë˜ìŠ¤ë³„ ë¶„í¬
        classes = ['person', 'car', 'bicycle', 'motorcycle', 'truck']
        class_counts = [45, 30, 15, 8, 12]
        
        fig2 = go.Figure(data=go.Pie(labels=classes, values=class_counts))
        fig2.update_layout(title="ê°ì²´ í´ë˜ìŠ¤ ë¶„í¬")
        
        return fig1, fig2
    
    # Gradio ì¸í„°í˜ì´ìŠ¤
    with gr.Blocks(title="AI ë³´ì•ˆ ì‹œìŠ¤í…œ", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # ğŸ”’ AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë³´ì•ˆ ì‹œìŠ¤í…œ
        
        ì‹¤ì‹œê°„ ê°ì²´ íƒì§€, ì¶”ì , ê·¸ë¦¬ê³  ì´ìƒ í–‰ë™ ê°ì§€
        """)
        
        with gr.Tab("ğŸ“¹ ë¹„ë””ì˜¤ ë¶„ì„"):
            with gr.Row():
                with gr.Column():
                    video_input = gr.Video(label="ë¹„ë””ì˜¤ ì—…ë¡œë“œ")
                    confidence_slider = gr.Slider(
                        minimum=0.1,
                        maximum=0.9,
                        value=0.5,
                        step=0.1,
                        label="íƒì§€ ì‹ ë¢°ë„ ì„ê³„ê°’"
                    )
                    analyze_btn = gr.Button("ë¶„ì„ ì‹œì‘", variant="primary")
                
                with gr.Column():
                    video_output = gr.Video(label="ë¶„ì„ ê²°ê³¼")
                    event_summary = gr.Textbox(label="ì´ë²¤íŠ¸ ìš”ì•½", lines=5)
            
            analyze_btn.click(
                fn=process_video_file,
                inputs=[video_input, confidence_slider],
                outputs=[video_output, event_summary]
            )
        
        with gr.Tab("ğŸ“Š í†µê³„ ëŒ€ì‹œë³´ë“œ"):
            with gr.Row():
                hourly_chart = gr.Plot(label="ì‹œê°„ëŒ€ë³„ í†µê³„")
                class_chart = gr.Plot(label="ê°ì²´ í´ë˜ìŠ¤ ë¶„í¬")
            
            refresh_btn = gr.Button("í†µê³„ ìƒˆë¡œê³ ì¹¨")
            refresh_btn.click(
                fn=generate_statistics,
                outputs=[hourly_chart, class_chart]
            )
        
        with gr.Tab("âš™ï¸ ì„¤ì •"):
            gr.Markdown("""
            ### ì‹œìŠ¤í…œ ì„¤ì •
            
            - **ì•Œë¦¼ ì´ë©”ì¼**: security@example.com
            - **ë…¹í™” ì €ì¥ ê²½ë¡œ**: /security_recordings
            - **ìµœëŒ€ ì¶”ì  ê°ì²´ ìˆ˜**: 50
            - **ì•Œë¦¼ ì¿¨ë‹¤ìš´**: 30ì´ˆ
            
            ### ì˜ì‹¬ í–‰ë™ ì„¤ì •
            
            - **ë°°íšŒ**: 60ì´ˆ ì´ìƒ ê°™ì€ ì¥ì†Œì— ë¨¸ë¬´ë¥´ê¸°
            - **ë¹ ë¥¸ ì›€ì§ì„**: 5 pixels/s ì´ìƒì˜ ì†ë„
            - **ë°©ì¹˜ëœ ë¬¼ì²´**: 5ë¶„ ì´ìƒ ì›€ì§ì„ ì—†ìŒ
            """)
        
        # ì˜ˆì‹œ ì¶”ê°€
        gr.Examples(
            examples=[
                ["example_security_1.mp4", 0.5],
                ["example_security_2.mp4", 0.7]
            ],
            inputs=[video_input, confidence_slider]
        )
    
    return demo

# ì‹œìŠ¤í…œ ì‹¤í–‰
def run_security_system():
    """ë³´ì•ˆ ì‹œìŠ¤í…œ ì‹¤í–‰"""
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘      ğŸ”’ AI ìŠ¤ë§ˆíŠ¸ ë³´ì•ˆ ì‹œìŠ¤í…œ ğŸ”’       â•‘
    â•‘                                      â•‘
    â•‘   ì‹¤ì‹œê°„ ê°ì‹œì™€ ì´ìƒ í–‰ë™ íƒì§€        â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    print("\nì‹¤í–‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ëª¨ë‹ˆí„°ë§")
    print("2. ë¹„ë””ì˜¤ íŒŒì¼ ë¶„ì„")
    print("3. ì›¹ ëŒ€ì‹œë³´ë“œ")
    
    choice = input("\nì„ íƒ (1-3): ")
    
    if choice == "1":
        system = SmartSecuritySystem()
        system.run_live_monitoring(source=0)  # ì›¹ìº 
        
    elif choice == "2":
        video_path = input("ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ: ")
        system = SmartSecuritySystem()
        system.run_live_monitoring(source=video_path)
        
    elif choice == "3":
        dashboard = create_security_dashboard()
        dashboard.launch(share=True)
    
    else:
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")

if __name__ == "__main__":
    run_security_system()