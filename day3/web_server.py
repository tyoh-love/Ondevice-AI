from flask import Flask, request, jsonify, send_from_directory
import whisper
import numpy as np
import wave
import tempfile
import os
import torch

app = Flask(__name__)

class WebWhisperSTT:
    """Web-based Whisper STT Service"""
    
    def __init__(self):
        self.models = {}
        print("ğŸŒ Web Whisper STT ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
    
    def load_model(self, model_size="base"):
        """ëª¨ë¸ ë¡œë“œ (ìºì‹±)"""
        if model_size not in self.models:
            print(f"ğŸ“¥ Whisper {model_size} ëª¨ë¸ ë¡œë“œ ì¤‘...")
            self.models[model_size] = whisper.load_model(model_size)
            print(f"âœ… {model_size} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        return self.models[model_size]
    
    def process_webm_audio(self, audio_file):
        """WebM ì˜¤ë””ì˜¤ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜"""
        try:
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(suffix='.webm', delete=False) as temp_file:
                audio_file.save(temp_file.name)
                temp_path = temp_file.name
            
            # ffmpegë¥¼ ì‚¬ìš©í•˜ì—¬ WAVë¡œ ë³€í™˜
            import subprocess
            wav_path = temp_path.replace('.webm', '.wav')
            
            subprocess.run([
                'ffmpeg', '-y', '-i', temp_path, 
                '-ar', '16000', '-ac', '1', '-c:a', 'pcm_s16le',
                wav_path
            ], capture_output=True, check=True)
            
            # WAV íŒŒì¼ ì½ê¸°
            with wave.open(wav_path, 'rb') as wav_file:
                frames = wav_file.readframes(-1)
                sound_info = np.frombuffer(frames, dtype=np.int16)
                audio_float32 = sound_info.astype(np.float32) / 32768.0
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            os.unlink(temp_path)
            os.unlink(wav_path)
            
            return audio_float32
            
        except subprocess.CalledProcessError as e:
            print(f"FFmpeg ì˜¤ë¥˜: {e}")
            return None
        except Exception as e:
            print(f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None
    
    def transcribe_audio(self, audio_data, language="ko", model_size="base"):
        """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        try:
            model = self.load_model(model_size)
            
            # ìµœì†Œ ê¸¸ì´ í™•ë³´
            if len(audio_data) < 16000:  # 1ì´ˆ ë¯¸ë§Œ
                audio_data = np.pad(audio_data, (0, 16000 - len(audio_data)))
            
            # Whisper ì‹¤í–‰
            result = model.transcribe(
                audio_data,
                language=None if language == "auto" else language,
                fp16=torch.cuda.is_available()
            )
            
            return result["text"].strip()
            
        except Exception as e:
            print(f"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}")
            return None

# ì „ì—­ STT ì¸ìŠ¤í„´ìŠ¤
stt_service = WebWhisperSTT()

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return send_from_directory('.', 'index.html')

@app.route('/transcribe', methods=['POST'])
def transcribe():
    """ìŒì„± ì¸ì‹ API"""
    try:
        # íŒŒì¼ í™•ì¸
        if 'audio' not in request.files:
            return jsonify({'success': False, 'error': 'ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'})
        
        audio_file = request.files['audio']
        if audio_file.filename == '':
            return jsonify({'success': False, 'error': 'íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'})
        
        # ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        language = request.form.get('language', 'ko')
        model_size = request.form.get('model', 'base')
        
        print(f"ğŸ¤ ìŒì„± ì¸ì‹ ìš”ì²­: ì–¸ì–´={language}, ëª¨ë¸={model_size}")
        
        # ì˜¤ë””ì˜¤ ì²˜ë¦¬
        audio_data = stt_service.process_webm_audio(audio_file)
        if audio_data is None:
            return jsonify({'success': False, 'error': 'ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨'})
        
        # ìŒì„± ì¸ì‹
        text = stt_service.transcribe_audio(audio_data, language, model_size)
        if text is None:
            return jsonify({'success': False, 'error': 'ìŒì„± ì¸ì‹ ì‹¤íŒ¨'})
        
        print(f"ğŸ“ ì¸ì‹ ê²°ê³¼: {text}")
        
        return jsonify({
            'success': True,
            'text': text,
            'language': language,
            'model': model_size
        })
        
    except Exception as e:
        print(f"ì„œë²„ ì˜¤ë¥˜: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/status')
def status():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    return jsonify({
        'status': 'running',
        'loaded_models': list(stt_service.models.keys()),
        'available_models': ['base', 'small', 'medium', 'large'],
        'cuda_available': torch.cuda.is_available()
    })

@app.route('/health')
def health():
    """í—¬ìŠ¤ ì²´í¬"""
    return jsonify({'status': 'healthy'})

if __name__ == '__main__':
    print("ğŸš€ Whisper Web STT ì„œë²„ ì‹œì‘ ì¤‘...")
    print("ğŸ“± ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:5000 ì ‘ì†")
    print("ğŸ¤ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”")
    print("âš¡ CUDA ì‚¬ìš© ê°€ëŠ¥:", torch.cuda.is_available())
    
    # FFmpeg ì„¤ì¹˜ í™•ì¸
    try:
        import subprocess
        subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)
        print("âœ… FFmpeg ì„¤ì¹˜ í™•ì¸ë¨")
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("âš ï¸  FFmpegê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤:")
        print("   Ubuntu/WSL: sudo apt install ffmpeg")
        print("   Windows: chocolateyë¡œ ì„¤ì¹˜í•˜ê±°ë‚˜ ê³µì‹ ì‚¬ì´íŠ¸ì—ì„œ ë‹¤ìš´ë¡œë“œ")
    
    app.run(host='0.0.0.0', port=5000, debug=True)